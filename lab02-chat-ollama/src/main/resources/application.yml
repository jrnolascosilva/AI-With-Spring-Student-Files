# TODO-04: Set the spring.application.name to "Lab02 Chat Ollama" or something similar.
# Set spring.main.web-application-type to none to run as a non-web application.
# Set spring.ai.retry.max-attempts to 1 to fail fast.
# Set spring.ai.retry.on-client-errors to false since there is typically no point in retrying such a request.
# Set spring.ai.ollama.base-url to http://localhost:11434, unless your container is running on a different URL.

spring:
  application.name: Lab2 Chat
  main.web-application-type: none     # Do not start a web server.
  ai:
      retry:
        max-attempts: 1                  # Fail fast on errors.
        on-client-errors: false           # No point in retrying client errors.
      ollama:
        base-url: http://127.0.0.1:11435  # Ollama server URL.
        chat:
          enabled: true              # Enable chat functionality.
          options:
            model: llama3.2:3b

