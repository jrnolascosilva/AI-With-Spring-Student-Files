  # TODO-04: 
  # Set `spring.application.name` to "Lab06 OpenAI Functions" or something similar.
  # Set `spring.main.web-application-type` to none to run as a non-web application.  Spring AI applications can run as web applications, but these exercises avoid this distraction.
  # Set `spring.ai.retry.max-attempts` to 1 to fail fast to save time if you have errors.
  # Set `spring.ai.retry.on-client-errors` to false since there is typically no point in retrying a client (vs server) error.
  # Set `spring.ai.openai.chat.enabled` to true to enable the chat model.
  # Set `spring.ai.openai.chat.options.model` to "gpt-35-turbo" to use the GPT-3.5 model, or allow it to default.
  
  # Configuration for running the application with Ollama and the gemma3:4b model
  spring:
    application:
      name: "Lab06 Ollama Functions"
    main:
      web-application-type: none     # Do not start a web server.
    jackson:
      deserialization:
        # This makes your app more robust against extra fields from the AI
        fail-on-unknown-properties: false
    ai:
      # General AI settings for fast failure on errors
      retry:
        max-attempts: 1
        on-client-errors: false

      # --- Ollama Configuration ---
      ollama:
        # This should point to your running Ollama instance.
        base-url: http://localhost:11434
        chat:
          options:
            # Specify the model you want to use.
            # Make sure you have pulled this model locally first!
            model: phi4-mini # OK
                  #gemma3:4b OK


